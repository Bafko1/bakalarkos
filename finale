import pandas as pd
import numpy as np
import os
import librosa
import soundfile as sf
import tempfile
import webbrowser
import sys
import warnings
from IPython.display import Audio
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import GRU, LSTM, LayerNormalization
from tensorflow.keras.regularizers import l2, l1
from tensorflow.keras.metrics import Precision, Recall, F1Score
from tensorflow.keras.optimizers import AdamW
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization

if not sys.warnoptions:
    warnings.simplefilter("ignore")
warnings.filterwarnings("ignore", category=DeprecationWarning) 

def load_iemocap_data(IEMOCAP_dir, csv_filename):
    iemocap_df = pd.read_csv(csv_filename)
    iemocap_df = iemocap_df[iemocap_df['emotion'] != 'xxx']
    iemocap_df['path'] = IEMOCAP_dir + "/" + iemocap_df['path']
    iemocap_df.rename(columns={'emotion': 'Emotions', 'path': 'Path'}, inplace=True)
    return iemocap_df[['Emotions', 'Path']]

IEMOCAP_dir = "IEMOCAP_full_release"
csv_filename = "iemocap_full_dataset.csv"  
IEMOCAP_df = load_iemocap_data(IEMOCAP_dir, csv_filename)

def load_data():
    Ravdess = "data"
    Crema = "AudioWAV"
    Tess = "zeny"
    Savee = "AudioData"
    ravdess_directory_list = os.listdir(Ravdess)
    file_emotion = []
    file_path = []
    for dir in ravdess_directory_list:
        actor = os.listdir(os.path.join(Ravdess, dir))
        for file in actor:
            part = file.split('.')[0]
            part = part.split('-')
            file_emotion.append(int(part[2]))
            file_path.append(os.path.join(Ravdess, dir, file))
    emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])
    path_df = pd.DataFrame(file_path, columns=['Path'])
    Ravdess_df = pd.concat([emotion_df, path_df], axis=1)
    Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)
    crema_directory_list = os.listdir(Crema)
    file_emotion = []
    file_path = []
    for file in crema_directory_list:
        file_path.append(os.path.join(Crema, file))
        part=file.split('_')
        if part[2] == 'SAD':
            file_emotion.append('sad')
        elif part[2] == 'ANG':
            file_emotion.append('angry')
        elif part[2] == 'DIS':
            file_emotion.append('disgust')
        elif part[2] == 'FEA':
            file_emotion.append('fear')
        elif part[2] == 'HAP':
            file_emotion.append('happy')
        elif part[2] == 'NEU':
            file_emotion.append('neutral')
        else:
            file_emotion.append('Unknown')
    emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])
    path_df = pd.DataFrame(file_path, columns=['Path'])
    Crema_df = pd.concat([emotion_df, path_df], axis=1)
    tess_directory_list = os.listdir(Tess)
    file_emotion = []
    file_path = []
    for dir in tess_directory_list:
        emotion = dir.split('_')[-1].lower()
        files = os.listdir(os.path.join(Tess, dir))
        for file in files:
            file_path.append(os.path.join(Tess, dir, file))
            file_emotion.append(emotion)
    emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])
    path_df = pd.DataFrame(file_path, columns=['Path'])
    Tess_df = pd.concat([emotion_df, path_df], axis=1)
    savee_directory_list = os.listdir(Savee)
    file_emotion = []
    file_path = []
    for subdir in savee_directory_list:
        subdir_path = os.path.join(Savee, subdir)
        if os.path.isdir(subdir_path):
            for file in os.listdir(subdir_path):
                if file.endswith(".wav"):  
                    file_path.append(os.path.join(subdir_path, file))
                    emotion_code = file[0]  
                    if emotion_code == 'a':
                        emotion = 'angry'
                    elif emotion_code == 'd':
                        emotion = 'disgust'
                    elif emotion_code == 'f':
                        emotion = 'fear'
                    elif emotion_code == 'h':
                        emotion = 'happy'
                    elif emotion_code == 'n':
                        emotion = 'neutral'
                    elif emotion_code == 'sa':
                        emotion = 'sad'
                    else:
                        emotion = 'surprise'
                    file_emotion.append(emotion)
    emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])
    path_df = pd.DataFrame(file_path, columns=['Path'])
    Savee_df = pd.concat([emotion_df, path_df], axis=1)
    data_path = pd.concat([Ravdess_df, Crema_df, Tess_df, Savee_df, IEMOCAP_df], axis = 0)
    data_path.to_csv("data_path.csv",index=False)
    return data_path

def noise_f(data):
    noise_amp = 0.035*np.random.uniform()*np.amax(data)
    data = data + noise_amp*np.random.normal(size=data.shape[0])
    return data

def stretch(data, rate=0.8):
    return librosa.effects.time_stretch(data, rate=rate)

def shift_f(data):
    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)
    return np.roll(data, shift_range)

def pitch_f(data, sampling_rate, pitch_factor=0.7):
    n_steps = 12 * np.log2(pitch_factor) 
    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=n_steps) 

def apply_augmentation(data, sample_rate):
    original = data
    noise = noise_f(data)
    rate = 0.8 
    stretch = librosa.effects.time_stretch(data, rate=rate)
    shift = shift_f(data)
    pitch = pitch_f(data, sample_rate)
    speed_rate = np.random.uniform(0.7, 1.3)
    speed_tune = librosa.effects.time_stretch(data, rate=speed_rate)
    return [original, noise, stretch, shift, pitch, speed_tune]

def normalize(data):
    return (data - np.min(data)) / (np.max(data) - np.min(data))

def extract_features(data, sample_rate):
    result = np.array([])
    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=13).T, axis=0)
    result = np.hstack((result, mfccs))
    chroma = np.mean(librosa.feature.chroma_stft(y=data, sr=sample_rate).T,axis=0)
    result = np.hstack((result, chroma))
    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T,axis=0)
    result = np.hstack((result, mel))
    contrast = np.mean(librosa.feature.spectral_contrast(y=data, sr=sample_rate).T,axis=0)
    result = np.hstack((result, contrast))
    tonnetz = np.mean(librosa.feature.tonnetz(y=data, sr=sample_rate).T,axis=0)
    result = np.hstack((result, tonnetz))
    return result

def extract_features_from_audio(data_path):
    X, Y = [], []
    for index, row in data_path.iterrows():
        file_path = row['Path']
        emotion = row['Emotions']
        data, sample_rate = librosa.load(file_path, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)
        augmented_data = apply_augmentation(data, sample_rate)
        for augmented in augmented_data:
            features = extract_features(augmented, sample_rate)
            X.append(features)
            Y.append(emotion)
    return np.array(X), np.array(Y)

data_path = load_data()
X, Y = extract_features_from_audio(data_path)

def prepare_data(X, Y):
    encoder = OneHotEncoder()
    Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, shuffle=True, random_state=42)
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    return X_train, X_test, Y_train, Y_test

X_train, X_test, Y_train, Y_test = prepare_data(X, Y)

def build_model(input_shape, num_classes):
    model = Sequential()
    model.add(Dense(256, activation='relu', input_shape=(input_shape,)))
    model.add(Dropout(0.5))
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

model = build_model(X_train.shape[1], Y_train.shape[1])
model.summary()

def train_model(model, X_train, Y_train, X_test, Y_test):
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1, mode='min')
    checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)
    callbacks = [early_stopping, reduce_lr, checkpoint]
    history = model.fit(X_train, Y_train, batch_size=32, epochs=100, validation_data=(X_test, Y_test), callbacks=callbacks)
    return history

history = train_model(model, X_train, Y_train, X_test, Y_test)

def evaluate_model(model, X_test, Y_test):
    Y_pred = model.predict(X_test)
    Y_pred_classes = np.argmax(Y_pred, axis=1)
    Y_true = np.argmax(Y_test, axis=1)
    cm = confusion_matrix(Y_true, Y_pred_classes)
    print(cm)
    print(classification_report(Y_true, Y_pred_classes))

evaluate_model(model, X_test, Y_test)
