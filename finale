import pandas as pd
import numpy as np
import os
import librosa
import soundfile as sf
import tempfile
import webbrowser
import sys
import warnings
from IPython.display import Audio
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import GRU, LSTM, LayerNormalization
from tensorflow.keras.regularizers import l2, l1
from tensorflow.keras.metrics import Precision, Recall, F1Score
from tensorflow.keras.optimizers import AdamW
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization
from tqdm.keras import TqdmCallback
from tqdm import tqdm
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape
from keras.preprocessing.image import ImageDataGenerator

emotion_mapping = {
    'neu': 'neutral',
    'fru': 'frustration',
    'xxx': 'unknown',
    'sur': 'surprise',
    'ang': 'angry',
    'hap': 'happy',
    'sad': 'sad',
    'exc': 'excited',
    'oth': 'other',
    'fea': 'fear',
    'dis': 'disgust'
}


if not sys.warnoptions:
    warnings.simplefilter("ignore")
warnings.filterwarnings("ignore", category=DeprecationWarning) 

def load_iemocap_data(IEMOCAP_dir, csv_filename):
    iemocap_df = pd.read_csv(csv_filename)
    
    # Vyradenie emócií 'xxx' a 'oth'
    iemocap_df = iemocap_df[~iemocap_df['emotion'].isin(['xxx', 'oth'])]
    
    iemocap_df['path'] = IEMOCAP_dir + "/" + iemocap_df['path']
    
    # Pridanie mapovania emócií
    iemocap_df['emotion'] = iemocap_df['emotion'].map(emotion_mapping)
    
    iemocap_df.rename(columns={'emotion': 'Emotions', 'path': 'Path'}, inplace=True)
    return iemocap_df[['Emotions', 'Path']]



IEMOCAP_dir = "IEMOCAP_full_release"
csv_filename = "iemocap_full_dataset.csv"  
IEMOCAP_df = load_iemocap_data(IEMOCAP_dir, csv_filename)

def load_data():
    Ravdess = "data"
    Crema = "AudioWAV"
    Tess = "zeny"
    Savee = "AudioData"
    ravdess_directory_list = os.listdir(Ravdess)
    file_emotion = []
    file_path = []
    for dir in ravdess_directory_list:
        actor = os.listdir(os.path.join(Ravdess, dir))
        for file in actor:
            part = file.split('.')[0]
            part = part.split('-')
            file_emotion.append(int(part[2]))
            file_path.append(os.path.join(Ravdess, dir, file))
    emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])
    path_df = pd.DataFrame(file_path, columns=['Path'])
    Ravdess_df = pd.concat([emotion_df, path_df], axis=1)
    Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)
    crema_directory_list = os.listdir(Crema)
    file_emotion = []
    file_path = []
    for file in crema_directory_list:
        file_path.append(os.path.join(Crema, file))
        part=file.split('_')
        if part[2] == 'SAD':
            file_emotion.append('sad')
        elif part[2] == 'ANG':
            file_emotion.append('angry')
        elif part[2] == 'DIS':
            file_emotion.append('disgust')
        elif part[2] == 'FEA':
            file_emotion.append('fear')
        elif part[2] == 'HAP':
            file_emotion.append('happy')
        elif part[2] == 'NEU':
            file_emotion.append('neutral')
        else:
            file_emotion.append('Unknown')
    emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])
    path_df = pd.DataFrame(file_path, columns=['Path'])
    Crema_df = pd.concat([emotion_df, path_df], axis=1)
    tess_directory_list = os.listdir(Tess)
    file_emotion = []
    file_path = []
    for dir in tess_directory_list:
        emotion = dir.split('_')[-1].lower()
        files = os.listdir(os.path.join(Tess, dir))
        for file in files:
            file_path.append(os.path.join(Tess, dir, file))
            file_emotion.append(emotion)
    emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])
    path_df = pd.DataFrame(file_path, columns=['Path'])
    Tess_df = pd.concat([emotion_df, path_df], axis=1)
    savee_directory_list = os.listdir(Savee)
    file_emotion = []
    file_path = []
    for subdir in savee_directory_list:
        subdir_path = os.path.join(Savee, subdir)
        if os.path.isdir(subdir_path):
            for file in os.listdir(subdir_path):
                if file.endswith(".wav"):  
                    file_path.append(os.path.join(subdir_path, file))
                    emotion_code = file[0]  
                    if emotion_code == 'a':
                        emotion = 'angry'
                    elif emotion_code == 'd':
                        emotion = 'disgust'
                    elif emotion_code == 'f':
                        emotion = 'fear'
                    elif emotion_code == 'h':
                        emotion = 'happy'
                    elif emotion_code == 'n':
                        emotion = 'neutral'
                    elif emotion_code == 'sa':
                        emotion = 'sad'
                    else:
                        emotion = 'surprise'
                    file_emotion.append(emotion)
    emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])
    path_df = pd.DataFrame(file_path, columns=['Path'])
    Savee_df = pd.concat([emotion_df, path_df], axis=1)
    data_path = pd.concat([Ravdess_df, Crema_df, Tess_df, Savee_df, IEMOCAP_df], axis = 0)
    data_path.to_csv("data_path.csv",index=False)
    return data_path

def noise_f(data):
    noise_amp = 0.035*np.random.uniform()*np.amax(data)
    data = data + noise_amp*np.random.normal(size=data.shape[0])
    return data

def stretch(data, rate=0.8):
    return librosa.effects.time_stretch(data, rate=rate)

def shift_f(data):
    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)
    return np.roll(data, shift_range)

def pitch_f(data, sampling_rate, pitch_factor=0.7):
    n_steps = 12 * np.log2(pitch_factor) 
    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=n_steps) 

def apply_augmentation(data, sample_rate):
    original = data
    noise = noise_f(data)
    rate = 0.8 
    stretch = librosa.effects.time_stretch(data, rate=rate)
    shift = shift_f(data)
    pitch = pitch_f(data, sample_rate)
    speed_rate = np.random.uniform(0.7, 1.3)
    speed_tune = librosa.effects.time_stretch(data, rate=speed_rate)
    return [original, noise, stretch, shift, pitch, speed_tune]

def normalize(data):
    return (data - np.min(data)) / (np.max(data) - np.min(data))

def extract_features(data, sample_rate):
    result = np.array([])
    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=13).T, axis=0)
    result = np.hstack((result, mfccs))
    chroma = np.mean(librosa.feature.chroma_stft(y=data, sr=sample_rate).T,axis=0)
    result = np.hstack((result, chroma))
    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T,axis=0)
    result = np.hstack((result, mel))
    contrast = np.mean(librosa.feature.spectral_contrast(y=data, sr=sample_rate).T,axis=0)
    result = np.hstack((result, contrast))
    tonnetz = np.mean(librosa.feature.tonnetz(y=data, sr=sample_rate).T,axis=0)
    result = np.hstack((result, tonnetz))
    return result

def extract_features_from_audio(data_path):
    X, Y = [], []
    for index, row in tqdm(data_path.iterrows(), total=data_path.shape[0], desc="Extracting Features"):
        file_path = row['Path']
        emotion = row['Emotions']
        data, sample_rate = librosa.load(file_path, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)
        augmented_data = apply_augmentation(data, sample_rate)
        for augmented in augmented_data:
            features = extract_features(augmented, sample_rate)
            X.append(features)
            Y.append(emotion)
    return np.array(X), np.array(Y)

data_path = load_data()
X, Y = extract_features_from_audio(data_path)

def prepare_data(X, Y):
    encoder = OneHotEncoder()
    Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, shuffle=True, random_state=42)
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    return X_train, X_test, Y_train, Y_test

X_train, X_test, Y_train, Y_test = prepare_data(X, Y)

X_train = X_train[..., np.newaxis]
X_test = X_test[..., np.newaxis]


def build_improved_model(input_shape, num_classes):
    model = Sequential()
    
    # Reshape 1D data to 2D with 1 channel
    model.add(Reshape((input_shape, 1, 1), input_shape=(input_shape, 1)))
    
    # First convolutional layer
    model.add(Conv2D(128, (3, 1), activation='relu'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D((2, 1)))
    model.add(Dropout(0.5))  # Increased dropout
    
    # Second convolutional layer
    model.add(Conv2D(256, (3, 1), activation='relu'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D((2, 1)))
    model.add(Dropout(0.5))  # Increased dropout
    
    # Third convolutional layer
    model.add(Conv2D(512, (3, 1), activation='relu'))  # New Conv layer
    model.add(BatchNormalization())
    model.add(MaxPooling2D((2, 1)))
    model.add(Dropout(0.5))  # Increased dropout
    
    # Fully connected layers
    model.add(Flatten())
    model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))
    model.add(BatchNormalization())
    model.add(Dropout(0.5))  # Increased dropout
    
    model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))
    model.add(BatchNormalization())
    model.add(Dropout(0.5))  # Increased dropout
    
    model.add(Dense(num_classes, activation='softmax'))
    
    # Compile the model with AdamW
    optimizer = AdamW(learning_rate=0.0005, weight_decay=1e-4)  # Reduced learning rate
    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', Recall(), Precision(), F1Score()])
  
    return model

# Create the improved model
input_shape = X_train.shape[1]
num_classes = Y_train.shape[1]
improved_model = build_improved_model(input_shape, num_classes)
improved_model.summary()

def train_model(model, X_train, Y_train, X_test, Y_test):
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1, mode='min')
    checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)
    callbacks = [early_stopping, reduce_lr, checkpoint]
    history = model.fit(X_train, Y_train, batch_size=32, epochs=200, validation_data=(X_test, Y_test), callbacks=callbacks)
    return history

history_improved = train_model(improved_model, X_train, Y_train, X_test, Y_test)

def evaluate_model(model, X_test, Y_test):
    Y_pred = model.predict(X_test)
    Y_pred_classes = np.argmax(Y_pred, axis=1)
    Y_true = np.argmax(Y_test, axis=1)
    cm = confusion_matrix(Y_true, Y_pred_classes)
    print(cm)
    print(classification_report(Y_true, Y_pred_classes))

evaluate_model(improved_model, X_test, Y_test)
